{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove PDF and use markdown instead for clarity\n",
    "\n",
    "# reader = PdfReader(\"resume/Resume-copy.pdf\")\n",
    "# linkedin = \"\"\n",
    "# for page in reader.pages:\n",
    "#     text = page.extract_text()\n",
    "#     if text:\n",
    "#         linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark  Leager   Ft  Lauderdale,  FL  •  markleager92@gmail.com  •  954-873-6757  •  https://github.com/mleager  DevOps  Engineer  |  Cloud  Infrastructure  |  CI/CD  Automation  |  Self-Taught  Technologist   Self-taught  DevOps  engineer  with  hands-on  experience  building,  deploying,  and  automating  cloud  \n",
      "infrastructure\n",
      " \n",
      "using\n",
      " \n",
      "AWS,\n",
      " \n",
      "Terraform,\n",
      " \n",
      "Kubernetes,\n",
      " \n",
      "Docker,\n",
      " \n",
      "and\n",
      " \n",
      "GitHub\n",
      " \n",
      "Actions.\n",
      "  Background  as  a  regional  manager  in  a  highly  regulated  industry,  with  proven  leadership,  cross-team  \n",
      "collaboration,\n",
      " \n",
      "and\n",
      " \n",
      "operations\n",
      " \n",
      "oversight.\n",
      "  Certified  in  Kubernetes,  Terraform,  and  AWS,  with  a  deep  commitment  to  automation,  observability,  and  \n",
      "infrastructure-as-code.\n",
      "  Certifications       Certified  Kubernetes  Administrator  (CKA)      AWS  Certified  Cloud  Practitioner      HashiCorp  Terraform  Associate      Linux  Administration  (self-paced  coursework)   Technical  Skills       Cloud  &  Infra:  AWS  (EKS,  ECS,  Lambda,  RDS,  S3,  CloudFront,  IAM,  CloudWatch)       Infrastructure  as  Code:  Terraform,  AWS  CloudFormation  (basic)       Containers:  Docker,  Kubernetes,  Amazon  ECS  and  EKS,  Helm       CI/CD  &  Automation:  GitHub  Actions,  AWS  CodePipeline,  Bash,  Makefiles       Monitoring:  Prometheus,  Grafana,  AWS  CloudWatch       Security:  Hashicorp  Vault,  IAM,  Parameter  Store       Programming/Scripting:  Go,  Javascript  (Vite,  Next),  Bash,  Python,  SQL       DevOps  Practices:  GitHub  Environments,  SSO,  Secrets  Management,  ALB/NLB,  Route53       Other:  Git,  GitHub,  Gitflow,  Ephemeral  Bastion  Hosts,  Role-Based  Access  (IAM)   Tools  &  Platforms  (Exposure  in  Local/Personal  Environments)       ArgoCD  –  GitOps-style  deployment  for  Kubernetes       Ansible  –  Basic  configuration  management  and  playbooks       Helm  –  Installed  and  deployed  charts  in  Kubernetes  clusters       Istio  –  Basic  service  mesh  routing  and  sidecar  injection       Jenkins  –  Set  up  basic  pipelines  and  runners  for  CI/CD       HashiCorp  Vault  –  Managed  secrets  for  local  services  and  dev  clusters  \n",
      "  DevOps  Projects   Infrastructure  Deployment  with  Terraform   -  Deployed  multi-environment  AWS  infrastructure  using  modular  Terraform  templates.   -  Managed  provisioning  of  EKS  clusters,  ECS  services,  RDS  (Aurora),  S3  buckets,  Route53  records,  \n",
      "and\n",
      " \n",
      "CloudFront\n",
      " \n",
      "distributions.\n",
      "  -  Enabled  custom  domain  routing  with  ALBs  +  HTTPS  certificates,  and  S3-based  frontend  hosting.   GitHub  Actions  CI/CD  Automation       Created  reusable  GitHub  workflows  to:   -  Plan/apply/destroy  Terraform  infrastructure   -  Sync  frontend  code  to  S3  and  invalidate  CloudFront  caches   -  Set  up  long-lived  and  short-lived  branches,  environments,  and  rulesets  with  branch  protection  \n",
      "policies\n",
      "  -  Reduced  deployment  friction  and  human  error  through  automated  S3  sync  and  rollback-friendly  \n",
      "deployments.\n",
      "  -  Deploy  to  development  and  staging  environments  to  ensure  seamless  integration  into  production.   -  Built  workflows  using  custom  Composite  Actions  and  Reusable  Workflows.   Containerized  Applications  &  Orchestration   -  Deployed  Dockerized  backend  applications  to  ECS,  pulling  built  images  from  ECR.   -  Containerized  apps  of  varying  programming  languages  using  multi-stage  builds  to  reduce  image  \n",
      "size.\n",
      "  -  Integrated  multiple  supporting  applications  using  Docker  Compose.   -  Built  a  webpage  to  serve  small  containerized  games,  each  in  its  own  isolated  Docker  environment.   Monitoring  &  Observability   -  Integrated  Prometheus  +  Grafana  dashboards  to  monitor  container  health,  resource  usage,  uptime  \n",
      "for\n",
      " \n",
      "anomalies.\n",
      "  -  Configured  CloudWatch  Alarms  to  trigger  Slack  alerts  for  ECS/Lambda  issues  and  performance  \n",
      "thresholds.\n",
      "       Professional  Experience   Regional  Manager  Royal  Pest  &  Termite  2020  -  Present   -  Managed  operations,  compliance,  and  safety  for  high-risk  products  (Vikane,  Zythor)  across  multiple  \n",
      "sites.\n",
      "  -  Created  AI  workflows  using  tools  like  n8n  for  lead  generation  and  customer  follow-up  systems,  \n",
      "internal\n",
      " \n",
      "management\n",
      " \n",
      "systems,\n",
      " \n",
      "inventory\n",
      " \n",
      "management\n",
      " \n",
      "and\n",
      " \n",
      "organization,\n",
      " \n",
      "internal\n",
      " \n",
      "knowledge\n",
      " \n",
      "databases\n",
      " \n",
      "for\n",
      " \n",
      "employees,\n",
      " \n",
      "and\n",
      " \n",
      "equipment\n",
      " \n",
      "management\n",
      "  -  Trained  teams  and  staff  on  the  use  of  custom  AI  workflows  and  systems  (sales,  office,  techs,  \n",
      "managers)\n",
      "  -  Created  AI  generated  videos  that  explain  our  business  and  service  offerings,  promotional  material,  \n",
      "etc.\n",
      "  -  Created  embedded  chatbot  in  homepage  as  well  as  emailed  proposals  to  answer  common  \n",
      "customer\n",
      " \n",
      "questions\n",
      "  -  Directed  cross-functional  teams  (field,  office,  logistics)  with  precision  and  urgency.   -  Documented  safety  protocols  and  operational  SOPs—translating  well  into  structured  DevOps  \n",
      "processes.\n",
      "  -  Oversaw  onboarding,  technical  training,  and  government  inspections,  ensuring  high  availability  and  \n",
      "accountability.\n",
      "  Education  &  Learning  Path   Self-Taught  DevOps  Engineer  2021  -  Present  Completed  intensive  self-learning  via  documentation,  open-source  projects,  and  structured  coursework  \n",
      "including:\n",
      "      freeCodeCamp,  KodeKloud,  Linux  Academy,  Nucamp       YouTube  channels  (Bret  Fisher,  DevOps  Journey,  Anton  Putra)       AWS  documentation,  Terraform  Registry,  Kubernetes.io   Skills  &  Traits       Strong  troubleshooting  mindset—able  to  trace,  debug,  and  resolve  issues  across  layers       Capable  of  onboarding  fast  to  new  systems  with  minimal  guidance       Natural  systems  thinker—automating  what’s  repetitive  and  documenting  what’s  not       Excellent  written/verbal  communication;  comfortable  bridging  technical  and  non-technical  teams   \n"
     ]
    }
   ],
   "source": [
    "# print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resume/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "with open(\"resume/resume.md\", \"r\", encoding=\"utf-8\") as r:\n",
    "    resume = r.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Mark Leager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{resume}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are acting as Mark Leager. You are answering questions on Mark Leager's website, particularly questions related to Mark Leager's career, background, skills and experience. Your responsibility is to represent Mark Leager for interactions on the website as faithfully as possible. You are given a summary of Mark Leager's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\n",
      "\n",
      "## Summary:\n",
      "I am Mark Leager, I am a DevOps engineer and have experience with many tools in the field. \n",
      "I am comfortable learning new technologies and implementations quickly, and am experienced at using AI to faciliate development and understanding.\n",
      "My current job is not in a technical field, but it certainly benefits from the use and integration of technolgy to increase performance and revenue.\n",
      "\n",
      "## LinkedIn Profile:\n",
      "Mark Leager\n",
      "\n",
      "## Contact\n",
      "954-873-6757  \n",
      "markleager92@gmail.com  \n",
      "\n",
      "\n",
      "## Certifications\n",
      "\n",
      "- Terraform Associate\n",
      "- Certified Kubernetes Administrator (CKA)\n",
      "- AWS Cloud Practitioner\n",
      "- GitOps with ArgoCD\n",
      "- Vault Associate\n",
      "\n",
      "\n",
      "## Profile\n",
      "\n",
      "DevOps Engineer who thrives on building systems that are reliable, efficient, and scalable.  \n",
      "Known for turning complex challenges into streamlined, automated solutions that reduce costs, minimize errors, and accelerate delivery.  \n",
      "Brings leadership experience from managing teams in high-pressure environments, with a focus on driving collaboration and aligning technology with real business impact.  \n",
      "\n",
      "\n",
      "## Devops Projects\n",
      "\n",
      "### AWS Infrastructure with Terraform\n",
      "Built scalable AWS infrastructure with secure, multi-environment deployments using HTTPS, ALBs, and CDNs.  \n",
      "Common services: EKS, ECS, RDS, S3, Route53, CloudFront, VPC, etc.\n",
      "\n",
      "### CI/CD Automation\n",
      "Developed pipelines using GitHub Actions and AWS CodePipeline to automate Terraform provisioning, S3 syncing, and CloudFront cache invalidation.  \n",
      "Included branch protections and rollback support.\n",
      "\n",
      "### Containerization & Deployment\n",
      "Containerized and deployed multi-language apps to ECS with Docker/ECR using multi-stage builds.  \n",
      "Orchestrated services with Docker Compose and deployed containerized games via a custom frontend.\n",
      "\n",
      "### Monitoring & Observability\n",
      "Implemented Prometheus, Grafana, and CloudWatch.  \n",
      "Prioritized key system metrics, monitored instability, and triggered alerts on anomalies and performance thresholds.\n",
      "\n",
      "### Security & Secrets Management\n",
      "Enhanced security with IAM, RBAC, OAuth, OIDC.  \n",
      "Implemented secrets management via AWS Secrets Manager, Parameter Store, HashiCorp Vault, and Bitnami Sealed Secrets.\n",
      "\n",
      "### AI Workflows and Implementations\n",
      "Created AI applications using Python and supporting tools and frameworks like n8n, Langchain, Vector Databases, multiple LLM Models and patterns, etc.\n",
      "AI applications were tailored to specific business logic and performance to improve various aspects of our workflows, customer support, and compliance/safety systems\n",
      "\n",
      "\n",
      "## Technical Skills\n",
      "\n",
      "### Cloud & Infrastructure:  \n",
      "AWS (EKS, ECS, Lambda, RDS, S3, CloudFront, IAM, CloudWatch)\n",
      "\n",
      "### Infrastructure as Code:  \n",
      "Terraform, AWS CloudFormation\n",
      "\n",
      "### Containers & Orchestration:  \n",
      "Docker, Kubernetes, Helm, ECS/EKS\n",
      "\n",
      "### CI/CD & Automation:  \n",
      "GitHub Actions, AWS CodePipeline, Bash, Makefiles\n",
      "\n",
      "### Monitoring & Observability:  \n",
      "Prometheus, Grafana, CloudWatch\n",
      "\n",
      "### Configuration Management:  \n",
      "Ansible, Helm, Kustomize, GitHub workflows\n",
      "\n",
      "### Security & Compliance:  \n",
      "IAM, HashiCorp Vault, Secrets Manager, Parameter Store\n",
      "\n",
      "### Programming & Scripting:  \n",
      "Go, Python, Bash, SQL, JavaScript (Vite, Next.js)\n",
      "\n",
      "### DevOps Practices:  \n",
      "GitHub Environments, SSO, DNS/load balancing (ALB/NLB, Route53)\n",
      "\n",
      "\n",
      "## Management & Admin Skills\n",
      "\n",
      "Managed cross-functional teams (field, office, logistics)\n",
      "\n",
      "Process development & compliance documentation (SOPs, safety protocols)\n",
      "\n",
      "Applied structured DevOps processes to business operations\n",
      "\n",
      "Strong troubleshooting mindset (debugging across layers)\n",
      "\n",
      "Quick to onboard with minimal guidance\n",
      "\n",
      "Excellent written/verbal communication\n",
      "\n",
      "Skilled at bridging technical and non-technical teams\n",
      "\n",
      "\n",
      "## Professional Experience\n",
      "\n",
      "### Regional Manager  \n",
      "Royal Pest & Termite – Fort Lauderdale, FL | 2020 – Present\n",
      "\n",
      "**TECHNICAL EXPERIENCE**\n",
      "\n",
      "**Purpose:** Create applications that directly improve financial performance and efficiency\n",
      "\n",
      "Designed custom AI workflows (with n8n, APIs, webhooks, Gmail, Sheets, etc.) for lead generation, customer follow-up, internal management systems, inventory tracking, and knowledge bases. [**strengthen weak points in our current systems & capitalize on leads**]  \n",
      "\n",
      "Trained staff on AI workflow usage (techs, sales, admin) [**coordinate with different teams and give hands-on demonstrations for easier adoption**].  \n",
      "\n",
      "Created AI-generated videos for training and promotional use [**allows for visual reinforcement of services provided and expected outcomes**].  \n",
      "\n",
      "Built an embedded chatbot for the homepage and proposal automation system [**improve customer experience while reducing the need for callbacks - faster close times**].  \n",
      "\n",
      "Developed an internal company database tool for techs to identify insect species and generate treatment plans [**improve technician’s ability to provide value and expertise**]\n",
      "\n",
      "**LEADERSHIP EXPERIENCE**\n",
      "\n",
      "Managed multi-site operations in a **highly regulated** industry, ensuring compliance with federal/state safety standards for hazardous products.  \n",
      "\n",
      "Directed cross-functional teams (field, logistics, admin) and implemented structured SOPs—skills directly applicable to DevOps process automation.  \n",
      "\n",
      "Led onboarding, training, and government inspection readiness, emphasizing reliability and accountability.  \n",
      "\n",
      "Taught commonly applied math involved in calculating cubic volume, determining gas expansion rates, and determining half-life times based on external variables\n",
      "\n",
      "\n",
      "### Previous Work \n",
      "\n",
      "Managed operations, compliance, and safety for high-risk products (Vikane, Zythor) across multiple sites.\n",
      "\n",
      "Directed cross-functional teams (field, office, logistics) with precision and urgency.\n",
      "\n",
      "Documented SOPs and safety protocols, translating into structured DevOps processes.\n",
      "\n",
      "Oversaw onboarding, technical training, and government inspections, ensuring accountability.\n",
      "\n",
      "Designed custom AI workflows (with n8n, APIs, webhooks, Gmail, Sheets, etc.) for lead generation, \n",
      "customer follow-up, internal management systems, inventory tracking, and knowledge bases.\n",
      "\n",
      "Trained staff on AI workflow usage (techs, sales, admin).\n",
      "\n",
      "Created AI-generated videos for training and promotional use.\n",
      "\n",
      "Built an embedded chatbot for the homepage and proposal automation system.\n",
      "\n",
      "Developed an internal company database tool for techs to identify insect species and generate treatment plans.\n",
      "\n",
      "\n",
      "## Education \n",
      "\n",
      "Self-Taught DevOps Engineer\n",
      "2021 – Present\n",
      "\n",
      "Learned through documentation, open-source projects, and structured courses.\n",
      "\n",
      "### Platforms & resources: \n",
      "freeCodeCamp, KodeKloud, Linux Academy, Nucamp, YouTube channels (Bret Fisher, DevOps Journey, Anton Putra), AWS Documentation, Terraform Registry, Kubernetes.io\n",
      "\n",
      "\n",
      "\n",
      "With this context, please chat with the user, always staying in character as Mark Leager.\n"
     ]
    }
   ],
   "source": [
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "    messages: list = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{resume}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GEMINI_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    # history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "    messages: list = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed or Evaluation(is_acceptable=False, feedback=\"No evaluation provided\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages: list = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
